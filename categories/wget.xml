<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>شاهینیسم (wget)</title><link>http://shahinism.github.io</link><description>بعضی وقت‌ها باید قبل از این که بتوانید راه بروید‌، بدوید‌!</description><lastBuildDate>Fri, 27 Sep 2013 19:22:59 GMT</lastBuildDate><generator>nikola</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>دانلود تمام عکس‌های SimpleDesktop با سه خط در Bash!</title><link>http://shahinism.github.io/posts/blog13910401dnlwd-tmm-khshy-simpledesktop-b-sh-kht-dr-bash.html</link><description>&lt;p&gt;&lt;/p&gt;&lt;a title="سینا احسانی در پلاس" href="https://plus.google.com/u/0/102916660970180940856" target="_blank"&gt;سینا احسانی&lt;/a&gt; عزیز در پلاس گفت که با VB برنامه‌ای نوشته که تمام عکس‌های سایت &lt;a title="SimpleDesktops official website!" href="http://simpledesktops.com/" target="_blank"&gt;SimpleDesktop&lt;/a&gt; را دانلود می‌کند‌. وقتی سایت را دیدم واقعا از تصاویرش خوشم آمد‌. خیلی وقت بود که پس‌زمینهٔ دسکتاپم یک تصویر ساده بود که ثابت مانده بود‌. این شد که تصمیم گرفتم من هم عکس‌ها را دانلود کنم‌. البته کاملا لینوکسی‌!
بررسی اولیه سایت معلوم کرد که پس از انتخاب عکس و کلیک آخر برای دانلود عکس شما با لینکی به صورت زیر طرف هستید‌:
&lt;div class="code"&gt;&lt;pre&gt;http://simpledesktops.com/download/?desktop&lt;span class="o"&gt;=&lt;/span&gt;301
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;همهٔ آدرس جز عدد ۳۰۱ در انتهایش ثابتند و آن عدد از ۱ یکی‌‌یکی زیاد می‌شود‌. هر کدام از این عکس‌ها پس از درخواست شدنشان به آدرس یکی از عکس‌های روی سرور اشاره می‌کنند‌. خوب دیگر داستان از این هم ساده‌تر می‌شود؟ کافیست که اراده کنیم و با یک حلقهٔ for اعداد را تولید کنیم و جلوی آدرس ثابتمان بنویسیم‌. پس می‌شود این:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre&gt;&lt;span class="c"&gt;#!/usr/bin/bash&lt;/span&gt;



&lt;span class="k"&gt;for &lt;/span&gt;i in &lt;span class="o"&gt;{&lt;/span&gt;1..5000&lt;span class="o"&gt;}&lt;/span&gt;

&lt;span class="k"&gt;do&lt;/span&gt;

&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;"http://simpledesktops.com/download/?desktop=$i"&lt;/span&gt;

&lt;span class="k"&gt;done&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;به بش گفتیم که هر بار یک عدد از یک تا پنج‌هزار (البته به ترتیب از کم به زیاد) تولید کن و در خروجی چاپ کن‌. یک بار اسکریپت را ران می‌کنیم و ... بعله خروجی دقیقا همان آدرس‌هایی که خواستیم می‌شود‌:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre&gt;...

http://simpledesktops.com/download/?desktop&lt;span class="o"&gt;=&lt;/span&gt;4995

http://simpledesktops.com/download/?desktop&lt;span class="o"&gt;=&lt;/span&gt;4996

http://simpledesktops.com/download/?desktop&lt;span class="o"&gt;=&lt;/span&gt;4997

http://simpledesktops.com/download/?desktop&lt;span class="o"&gt;=&lt;/span&gt;4998

http://simpledesktops.com/download/?desktop&lt;span class="o"&gt;=&lt;/span&gt;4999

http://simpledesktops.com/download/?desktop&lt;span class="o"&gt;=&lt;/span&gt;5000
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;حالا کافیست در اسکریپت به جای echo که هر چه جلویش باشد را در خروجی استاندارد چاپ می‌کند یک wget بنویسیم تا آدرس‌های جلویش را دانلود کند‌. اما نه‌! در اولین اقدام تیرمان خطا رفت‌! در سرور‌های Apache یک فایلی هست به اسم ‎.htaccess و همان‌طور که از نامش معلوم است کارش این است که کنترل کند چه کسی به کجا دسترسی دارد‌. هر نرم‌افزاری هم که به یکی از این سرور‌ها درخواست بدهد موظف است اول خودش را معرفی کند‌. خوب wget که از نامش فساد می‌بارد عموما از طرف چنین سایت‌هایی مسدود می‌شود‌.&lt;/p&gt;
&lt;p&gt;این است که باید به wget بگوییم نقابش را به صورت بزند و دوباره اقدام کند‌. اینبار اسکریپتمان این شکلی می‌شود‌:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre&gt;&lt;span class="c"&gt;#!/usr/bin/bash&lt;/span&gt;



&lt;span class="k"&gt;for &lt;/span&gt;i in &lt;span class="o"&gt;{&lt;/span&gt;100..5000&lt;span class="o"&gt;}&lt;/span&gt;

&lt;span class="k"&gt;do&lt;/span&gt;

wget -U &lt;span class="s2"&gt;"Mozilla/5.0 (Windows NT 5.1; rv:10.0.2) Gecko/20100101 Firefox/10.0.2"&lt;/span&gt; &lt;span class="s2"&gt;"http://simpledesktops.com/download/?desktop=$i"&lt;/span&gt;

&lt;span class="k"&gt;done&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;و بعله‌! ران می‌کنیم و خیلی خوشکل اقدام به دانلود عکس‌ها می‌کنیم ;-)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;پی‌نوشت:&lt;/strong&gt; در حین جستجو برای نوشتن این اسکریپت کشف کردم که قبلا اسکریپت‌هایی با Python یا PHP هم برای شیره‌کشی از این سایت نوشته شده‌. ولی این اسکریپت از همه‌شان کوتاه‌تر بود و خوب سادگی زیبـــــاست ;-)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;پی‌نوشت ۲&lt;/strong&gt;: دیگر خودتان حواستان باشد که ‎#!‎/‎usr/bin/bash آدرس bash سیستم من است و می‌توانید با یک whereis bash پیدا کنید که مال شما کجاست‌!&lt;/p&gt;
&lt;p&gt;&lt;span style="color: #ff0000;"&gt;&lt;strong&gt;پی‌نوشت ۳:&lt;/strong&gt; ممکنه بعد از دانلود متوجه بشین که فایل‌های دانلودی با یه همچین اسمایی ذخیره می‌شن index.html?desktop=100 اتفاقی که برای من روی سرور آرچ افتاد‌. عجیب بود که اسم فایل درست رو می‌دید ولی خودش از رو این Querystring ساخته شده اسم رو می‌نوشت‌. پس از جستجو کشف کردم که باید آپشن زیر هم به wget اضافه بشه:&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;```bash&lt;/p&gt;
&lt;p&gt;--content-disposition&lt;/p&gt;
&lt;p&gt;```&lt;/p&gt;</description><category>bash</category><category>echo</category><category>wget</category><category>اینترنت</category><category>برنامه نویسی</category><category>نرم افزار</category><category>گنو/لینوکس</category><guid>http://shahinism.github.io/posts/blog13910401dnlwd-tmm-khshy-simpledesktop-b-sh-kht-dr-bash.html</guid><pubDate>Thu, 21 Jun 2012 20:15:36 GMT</pubDate></item><item><title>چ‌چ‌چ (۹): چطور به صورت فله‌ای لینک‌های یوتیوب را از وب‌سایتی استخراج و دانلود کنیم‌!</title><link>http://shahinism.github.io/posts/blog13900926chchch-9-chtwr-bh-swrt-flhy-lynkhh.html</link><description>&lt;p&gt;&lt;/p&gt;&lt;p&gt;ببخشید که تیتری از این ساده‌تر و گو‌یاتر پیدا نکردم‌. ولی خوب اصل موضوع خیلی قشنگ چالش بر‌انگیز است‌. مساله این است‌:
&lt;/p&gt;&lt;blockquote&gt;سایتی به این شکل داریم (‌&lt;a title="the newboston php video" href="http://thenewboston.org/list.php?cat=11" target="_blank"&gt;لینک را باز کنید‌&lt;/a&gt;) که شامل یک لیست از پیوند به صفحات دیگرش است که در آن‌ها علاوه بر قابلیت نمایش ویدیو‌، لینک یوتیوب همان ویدیو وجود دارد‌. حجم پیوند‌ها برابر ۲۰۰ عدد است&lt;/blockquote&gt;
&lt;p&gt;کار عادی‌اش به این صورت است که بنشینیم و با حوصله تک تک لینک‌ها را کپی پیست کرده و جایی ذخیره کنیم‌. ولی با وجود دویست صفحه و لینک‌، کمی (‌خیلی‌) خسته کننده (‌خریت‌ به معنای واقعی کلمه‌، البته ببخشید ;-)) است. خوب جواب مساله را خودم هم نمی‌دانستم‌، ولی مطمئن بودم‌، با ابزار‌های گنو‌/‌لینوکسی‌، نتیجه‌ی خیلی خوبی خواهم گرفت‌. اولین کاری که به فکرم رسید‌، دانلود صفحه‌ی اصلی و صفحه‌های پیوند شده به هر لینک بود که با wget خیلی خوب بلد بودم! به این صورت‌:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre&gt;wget -rl1 http://thenewboston.org/list.php?cat&lt;span class="o"&gt;=&lt;/span&gt;11
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;خوب نتیجه‌ مجموعه‌ای از فایل‌ها بود که با اسم‌هایی شبیه به آدرس‌شان در پوشه‌ی جاری ذخیره شده بود. با استفاده از آرگومان‌های rl1 به wget فهماندم که صفحه‌ی حاضر را به عمق یک صفحه رو به جلو دانلود کند‌. حالا مساله‌ی سخت این‌جا بود که چطور به grep بفهمانیم که چه چیزی را (‌در این‌جا لینک ویدیو در یوتیوب‌) برایمان جدا کند‌. دستوری که با دفعات زیادی آزمون و خطا نتیجه داد‌، به این صورت بود‌: &lt;span style="color: #ff6600;"&gt;(‌برای دیدن دستور کامل‌تر به آخر مطلب رجوع کنید‌، ویرایش۱)&lt;/span&gt;&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre&gt;grep -ohE &lt;span class="s2"&gt;"http://www.youtube.com/watch\?v=[[:alnum:]-]{11}"&lt;/span&gt; * &amp;amp;gt; list
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;کار این دستور این است که یک لیست از الگوی داده شده را ایجاد و در فایل list ذخیره کند‌. آرگومان‌های ohE به طور خلاصه به grep می‌فهمانند‌ که فقط عبارت داخل پرانتز را در فایل‌ها پیدا کند و در خروجی نمایش دهد‌. قسمت جالب قضیه که بیشتر از همه وقتم را گرفت بخش زیر بود‌:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre&gt;&lt;span class="o"&gt;[[&lt;/span&gt;:alnum:&lt;span class="o"&gt;]&lt;/span&gt;-&lt;span class="o"&gt;]{&lt;/span&gt;11&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;که به grep می‌گفت ترکیبی از حروف و ارقام را به تعداد یازده عدد قبول کند‌. در مورد این عبارت‌ها در آینده‌ای نزدیک پستی در شاهینیسم خواهیم داشت.&lt;/p&gt;
&lt;p&gt;برای دانلود لینک‌ها هم می‌توانید همان فایل خروجی را به صورت زیر به youtube-dl بدهید‌:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre&gt;youtube-dl -ta list
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;البته سرعت دانلود youtube-dl واقعا پایین است‌. روی سروری با دانلود عادی ده مگ‌، سرعت به زور می‌توانست به چهل کیلوبایت برسد‌. پیشنهاد من به شما‌، نصب یک نسخه از RapidLeech است‌. سرعت و کاربرد بسیار بهتری دارد ;-)&lt;/p&gt;
&lt;p&gt;ویرایش ۱: بعد از مدتی استفاده از این دستور‌، فهمیدم که از اونجایی که توی آدرس‌های Youtube امکان وجود آندرلاین هم هست‌، تعدادی از لینک‌ها رو با دستور بالا از دست می‌دیم‌. به همین دلیل دنبال یه راه دیگه گشتم‌، و سر‌انجام به دستور زیر رسیدم که نتیجه‌ی خیلی قابل قبول‌تری می‌ده‌:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre&gt;grep -ohE &lt;span class="s2"&gt;"http://www.youtube.com/watch\?v=[[:alnum:](-|_)]{11}"&lt;/span&gt; * | uniq &amp;amp;gt; list2
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;همچنین توی این دستور با استفاده از uniq از تکرار لینک‌ها در صفحه خروجی جلوگیری می‌شه ;-)&lt;/p&gt;</description><category>grep</category><category>RapidLeech</category><category>wget</category><category>youtube</category><category>youtube-dl</category><category>چی‌؟ چرا‌؟ چگونه‌؟</category><guid>http://shahinism.github.io/posts/blog13900926chchch-9-chtwr-bh-swrt-flhy-lynkhh.html</guid><pubDate>Sat, 17 Dec 2011 15:33:05 GMT</pubDate></item></channel></rss>